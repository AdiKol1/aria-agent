# Aria Agent - macOS Desktop Assistant
# Python 3.11+

# Core
anthropic>=0.39.0
openai>=1.0.0
# google-genai - REMOVED in v2.0 (Moshi replaced Gemini Live)

# =============================================================================
# DAEMON MODE (v4.0)
# =============================================================================
fastapi>=0.109.0
uvicorn>=0.27.0
python-multipart>=0.0.6
websockets>=12.0
httpx>=0.26.0

# Telegram Bridge
python-telegram-bot>=21.0

# macOS Menubar App
rumps>=0.4.0

# Wake Word Detection
pvporcupine>=3.0.0

# Screen Capture & Computer Control
pyautogui>=0.9.54
pynput>=1.7.6  # Mouse/keyboard tracking for proactive vision
pillow>=10.0.0
pyobjc-core>=10.0
pyobjc-framework-Cocoa>=10.0
pyobjc-framework-Quartz>=10.0
pyobjc-framework-ScreenCaptureKit>=10.0

# Audio
pyaudio>=0.2.14
numpy>=1.24.0
sounddevice>=0.4.6
# websockets - REMOVED in v2.0 (Moshi replaced OpenAI Realtime)

# Gesture Recognition
mediapipe>=0.10.0
opencv-python>=4.8.0

# Memory & Storage
chromadb>=0.4.0
rank-bm25>=0.2.2

# Utilities
python-dotenv>=1.0.0
pydantic>=2.0.0
pyperclip>=1.8.0

# MCP Server uses built-in JSON-RPC (no external dependency needed)

# =============================================================================
# Voice System v2.0: Moshi + Claude
# =============================================================================
# Moshi MLX provides local full-duplex voice I/O on Apple Silicon
# with 160-200ms latency, replacing the expensive OpenAI Realtime API

# Moshi for Apple Silicon (local voice I/O)
moshi-mlx>=0.1.0  # pip install moshi-mlx OR pip install git+https://github.com/kyutai-labs/moshi.git#subdirectory=moshi_mlx
mlx>=0.5.0  # Apple Silicon ML framework
mlx-whisper>=0.1.0  # Local whisper for wake word detection

# Audio processing
soundfile>=0.12.0

# HTTP client (for web search, etc.)
requests>=2.31.0

# =============================================================================
# Voice System v3.0: Pipecat Pipeline
# =============================================================================
# Production-ready voice pipeline with:
# - Deepgram STT (real-time streaming)
# - ElevenLabs TTS (natural voice)
# - Silero VAD (interruption handling)
pipecat-ai[anthropic,deepgram,elevenlabs,silero,local]>=0.0.60

# =============================================================================
# REMOVED in v2.0 (Qwen Hybrid replaced by Moshi):
# - transformers (Qwen model)
# - accelerate (Qwen model)
# - bitsandbytes (Qwen quantization)
# - google-genai (Gemini Live API)
# - websockets (OpenAI Realtime API)
# =============================================================================
